{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup** <br>\n",
    "    \n",
    "\n",
    "- Clean up your files so that only the feilds you want to do the matching on remain <br>\n",
    "- Give feilds in each dataframe unique names <br>\n",
    "- Make sure the index in sequential (i.e. 1,2,3 and NOT 1,2...4) <br><br>\n",
    "\n",
    "\n",
    "**matchy_mcmatch_face()** <br> \n",
    "\n",
    "- **Parameters:** <br>\n",
    "    - **new_data** : data you want to find matches for <br>\n",
    "    - **lookup_data** : data you want to search in for matches <br>\n",
    "    - **num_top_matches** : number of matches to return <br>\n",
    "\n",
    "- **Returned Objects:** <br>\n",
    "    - **results_df**: indexs (0_x,1_x,etc,) and L2 distances (0_y,1_y,etc,) match results for each record in the new_data. <br>\n",
    "    - **lookup_df**: the index and metadata for the table you are searching.  The function only returns data for the first match for simplicity.  You can append metadata for the subsequent matches as needed\n",
    "    \n",
    "- **Other Notes**\n",
    "    - SKlearn TfidfVectorizer: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "    - FAISS: https://github.com/facebookresearch/faiss/wiki\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from faiss-cpu) (1.14.3)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/facebookresearch/faiss/issues/821\n",
    "!pip install faiss-cpu --no-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import scipy.spatial as sp\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "import faiss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_raw = '.csv'\n",
    "two_raw = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df = pd.read_csv(one_raw)\n",
    "two_df = pd.read_csv(two_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "one_df = one_df[one_df['address'] != '\\\\N']\n",
    "one_df['address_len'] = [len(str(x)) for x in ib_df['address']]\n",
    "one_df = one_df[one_df['address_len'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to reset twice because removing records messed up index\n",
    "one_df = one_df.reset_index()\n",
    "one_df = one_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df = one_df[[\n",
    "     'store_number',\n",
    "     'address',\n",
    "     'city',\n",
    "     'state',\n",
    "     'zip',\n",
    "          ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df = one_df.rename(columns={\n",
    "                 'store_number':'ib_store_number',\n",
    "                 'address':'ib_address',\n",
    "                 'city':'ib_city',\n",
    "                 'state':'ib_state',\n",
    "                 'zip':'ib_zip'\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15116, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ib_store_number</th>\n",
       "      <th>ib_address</th>\n",
       "      <th>ib_city</th>\n",
       "      <th>ib_state</th>\n",
       "      <th>ib_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4597</td>\n",
       "      <td>886 Niagara Falls Blvd</td>\n",
       "      <td>North Tonawanda</td>\n",
       "      <td>NY</td>\n",
       "      <td>14120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8478</td>\n",
       "      <td>820 Cooper St</td>\n",
       "      <td>Woodbury</td>\n",
       "      <td>NJ</td>\n",
       "      <td>08096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>614</td>\n",
       "      <td>803 New Franklin Rd</td>\n",
       "      <td>Lagrange</td>\n",
       "      <td>GA</td>\n",
       "      <td>30240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ib_store_number              ib_address          ib_city ib_state ib_zip\n",
       "0            4597  886 Niagara Falls Blvd  North Tonawanda       NY  14120\n",
       "1            8478           820 Cooper St         Woodbury       NJ  08096\n",
       "2             614     803 New Franklin Rd         Lagrange       GA  30240"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_df = two_df[[\n",
    " 'Store Nbr',\n",
    " 'Street Address',\n",
    " 'City',\n",
    " 'State',\n",
    " 'Zip Code'\n",
    "          ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_df = two_df.rename(columns={\n",
    "                 'Store Nbr':'NEW_store_number',\n",
    "                 'Street Address':'NEW_address',\n",
    "                 'City':'NEW_city',\n",
    "                 'State':'NEW_state',\n",
    "                 'Zip Code':'NEW_zip'\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4372, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEW_store_number</th>\n",
       "      <th>NEW_address</th>\n",
       "      <th>NEW_city</th>\n",
       "      <th>NEW_state</th>\n",
       "      <th>NEW_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2110 W WALNUT ST</td>\n",
       "      <td>ROGERS</td>\n",
       "      <td>AR</td>\n",
       "      <td>72756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161 N WALMART DR</td>\n",
       "      <td>HARRISON</td>\n",
       "      <td>AR</td>\n",
       "      <td>72601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30983 HIGHWAY 441 S</td>\n",
       "      <td>COMMERCE</td>\n",
       "      <td>GA</td>\n",
       "      <td>30529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NEW_store_number          NEW_address  NEW_city NEW_state  NEW_zip\n",
       "0                 1     2110 W WALNUT ST    ROGERS        AR    72756\n",
       "1                 2     161 N WALMART DR  HARRISON        AR    72601\n",
       "2                 3  30983 HIGHWAY 441 S  COMMERCE        GA    30529"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matchy McMatchface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchy_mcmatchface(new_data,lookup_data,num_top_matches):\n",
    "    \n",
    "    new_data = new_data.reset_index()\n",
    "    lookup_data = lookup_data.reset_index()\n",
    "    \n",
    "    # make concatenated feilds excluding 1st feild \n",
    "    new_data['all_fields'] = new_data[new_data.columns[1:]].apply(lambda x: ' '.join(x.dropna().astype(str)),axis=1)\n",
    "    lookup_data['all_fields'] = lookup_data[lookup_data.columns[1:]].apply(lambda x: ' '.join(x.dropna().astype(str)),axis=1)\n",
    "    \n",
    "    # make corpus\n",
    "    corp_1 = list(new_data['all_fields'])\n",
    "    corp_2 = list(lookup_data['all_fields'])\n",
    "    ALL_corp = corp_1 + corp_2\n",
    "    print(\"corpus created...\")\n",
    "\n",
    "    # matrix of token counts\n",
    "    count_vect = CountVectorizer()\n",
    "    X_train_counts = count_vect.fit_transform(ALL_corp)\n",
    "    full_bow_df = pd.DataFrame(X_train_counts.toarray(),columns=count_vect.get_feature_names())\n",
    "    print(\"matrix of tokens counts created...\")\n",
    "    \n",
    "    #Remove tokens that only happen once and cannot be in both dataframes\n",
    "    cols = ['counts']\n",
    "    token_count_df = pd.DataFrame(full_bow_df.sum(axis = 0, skipna = True)).sort_values(by=[0],ascending=False)\n",
    "    token_count_df.columns = cols \n",
    "    trim_token_count_df = token_count_df[token_count_df['counts'] > 1]\n",
    "    \n",
    "    # Get # of features for tf-idf\n",
    "    max_features = len(trim_token_count_df)\n",
    "    \n",
    "    #create tf-idf matrix\n",
    "    tf = TfidfVectorizer(max_features=max_features).fit(ALL_corp)  \n",
    "    trsfm = tf.fit_transform(ALL_corp) \n",
    "\n",
    "    full_trsfm_df = pd.DataFrame(trsfm.toarray(),columns=tf.get_feature_names())\n",
    "    print(\"Possible number of features to use for Tf-idf: \" + str(max_features))\n",
    "    \n",
    "    dim = max_features\n",
    "    \n",
    "    # split & turn list of list into dataframe\n",
    "    new_mat = pd.DataFrame(full_trsfm_df[:len(corp_1)])\n",
    "    lookup_mat = pd.DataFrame(full_trsfm_df[len(corp_1):])\n",
    "\n",
    "    \n",
    "    # dataframe into array with float32 FAISS requires....if not using svd\n",
    "    new_mat = new_mat.values.tolist()\n",
    "    new_mat_arr = np.asarray(new_mat,dtype=np.float32)\n",
    "\n",
    "    lookup_mat = lookup_mat.values.tolist()\n",
    "    lookup_mat_arr = np.asarray(lookup_mat,dtype=np.float32)\n",
    "\n",
    "    # build the index\n",
    "    lookup_index = faiss.IndexFlatL2(int(dim))   \n",
    "    \n",
    "    # add vectors to the index\n",
    "    lookup_index.add(lookup_mat_arr) \n",
    "    print(\"FAISS lookup table built...\")\n",
    "    \n",
    "    # Search lookup data with new data\n",
    "    print(\"k-means search in process...\")\n",
    "    D, I = lookup_index.search(new_mat_arr, num_top_matches)   \n",
    "    \n",
    "    # make dataframes\n",
    "    I_results_df = pd.DataFrame(I)\n",
    "    D_results_df = pd.DataFrame(D)\n",
    "    \n",
    "    I_results_df = I_results_df.reset_index()\n",
    "    D_results_df = D_results_df.reset_index()\n",
    "    \n",
    "    results_df = pd.merge(I_results_df,\n",
    "                          D_results_df,\n",
    "                          left_on='index',\n",
    "                          right_on='index')\n",
    "    \n",
    "    \n",
    "    new_data = new_data.drop(['all_fields'], axis=1)\n",
    "    lookup_data = lookup_data.drop(['all_fields'], axis=1)\n",
    "\n",
    "    \n",
    "    results_df = pd.merge(results_df,\n",
    "                          new_data,\n",
    "                          left_on='index',\n",
    "                          right_on='index')\n",
    "    \n",
    "    results_df = pd.merge(results_df,\n",
    "                          lookup_data,\n",
    "                          left_on='0_x',\n",
    "                          right_on='index')\n",
    "    \n",
    "    results_df = results_df.drop(['index_y'], axis=1)\n",
    "    results_df = results_df.rename(columns={'index_x':'new_data_index'})\n",
    "    \n",
    "    print(\"Finished!\")\n",
    "\n",
    "    return results_df,lookup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus created...\n",
      "matrix of tokens counts created...\n",
      "Possible number of features to use for Tf-idf: 15177\n",
      "FAISS lookup table built...\n",
      "k-means search in process...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "results_df,lookup_data = matchy_mcmatchface(two_df,one_df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_data_index</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>3_y</th>\n",
       "      <th>...</th>\n",
       "      <th>NEW_store_number</th>\n",
       "      <th>NEW_address</th>\n",
       "      <th>NEW_city</th>\n",
       "      <th>NEW_state</th>\n",
       "      <th>NEW_zip</th>\n",
       "      <th>ib_store_number</th>\n",
       "      <th>ib_address</th>\n",
       "      <th>ib_city</th>\n",
       "      <th>ib_state</th>\n",
       "      <th>ib_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14547</td>\n",
       "      <td>12691</td>\n",
       "      <td>342</td>\n",
       "      <td>14687</td>\n",
       "      <td>3334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2110 W WALNUT ST</td>\n",
       "      <td>ROGERS</td>\n",
       "      <td>AR</td>\n",
       "      <td>72756</td>\n",
       "      <td>0</td>\n",
       "      <td>2110 W WALNUT ST</td>\n",
       "      <td>ROGERS</td>\n",
       "      <td>AR</td>\n",
       "      <td>72756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7884</td>\n",
       "      <td>3837</td>\n",
       "      <td>676</td>\n",
       "      <td>706</td>\n",
       "      <td>756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>161 N WALMART DR</td>\n",
       "      <td>HARRISON</td>\n",
       "      <td>AR</td>\n",
       "      <td>72601</td>\n",
       "      <td>0</td>\n",
       "      <td>161 N Walmart Dr</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>AR</td>\n",
       "      <td>72601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8793</td>\n",
       "      <td>8210</td>\n",
       "      <td>10841</td>\n",
       "      <td>5762</td>\n",
       "      <td>6336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>30983 HIGHWAY 441 S</td>\n",
       "      <td>COMMERCE</td>\n",
       "      <td>GA</td>\n",
       "      <td>30529</td>\n",
       "      <td>3</td>\n",
       "      <td>30983 Highway 441 S</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>GA</td>\n",
       "      <td>30529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14505</td>\n",
       "      <td>3425</td>\n",
       "      <td>4528</td>\n",
       "      <td>13549</td>\n",
       "      <td>9048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728455</td>\n",
       "      <td>0.728455</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2901 HIGHWAY 412 E</td>\n",
       "      <td>SILOAM SPRINGS</td>\n",
       "      <td>AR</td>\n",
       "      <td>72761</td>\n",
       "      <td>4</td>\n",
       "      <td>2901 Highway 412 E</td>\n",
       "      <td>Siloam Springs</td>\n",
       "      <td>AR</td>\n",
       "      <td>72761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>725</td>\n",
       "      <td>93</td>\n",
       "      <td>906</td>\n",
       "      <td>766</td>\n",
       "      <td>704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1155 HWY 65 NORTH</td>\n",
       "      <td>CONWAY</td>\n",
       "      <td>AR</td>\n",
       "      <td>72032</td>\n",
       "      <td>0</td>\n",
       "      <td>1155 HWY 65 NORTH</td>\n",
       "      <td>CONWAY</td>\n",
       "      <td>AR</td>\n",
       "      <td>72032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_data_index    0_x    1_x    2_x    3_x   4_x  0_y  1_y       2_y  \\\n",
       "0               0  14547  12691    342  14687  3334  0.0  0.0  0.000000   \n",
       "1               1   7884   3837    676    706   756  0.0  0.0  1.000000   \n",
       "2               2   8793   8210  10841   5762  6336  0.0  0.0  0.000000   \n",
       "3               3  14505   3425   4528  13549  9048  0.0  0.0  0.728455   \n",
       "4               4    725     93    906    766   704  0.0  0.0  0.000000   \n",
       "\n",
       "        3_y  ...  NEW_store_number          NEW_address        NEW_city  \\\n",
       "0  0.035951  ...                 1     2110 W WALNUT ST          ROGERS   \n",
       "1  1.000000  ...                 2     161 N WALMART DR        HARRISON   \n",
       "2  0.000000  ...                 3  30983 HIGHWAY 441 S        COMMERCE   \n",
       "3  0.728455  ...                 4   2901 HIGHWAY 412 E  SILOAM SPRINGS   \n",
       "4  0.000000  ...                 5    1155 HWY 65 NORTH          CONWAY   \n",
       "\n",
       "  NEW_state NEW_zip  ib_store_number           ib_address         ib_city  \\\n",
       "0        AR   72756                0     2110 W WALNUT ST          ROGERS   \n",
       "1        AR   72601                0     161 N Walmart Dr        Harrison   \n",
       "2        GA   30529                3  30983 Highway 441 S        Commerce   \n",
       "3        AR   72761                4   2901 Highway 412 E  Siloam Springs   \n",
       "4        AR   72032                0    1155 HWY 65 NORTH          CONWAY   \n",
       "\n",
       "  ib_state ib_zip  \n",
       "0       AR  72756  \n",
       "1       AR  72601  \n",
       "2       GA  30529  \n",
       "3       AR  72761  \n",
       "4       AR  72032  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
